{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ceffb5",
   "metadata": {},
   "source": [
    "# Análise de Apólices e Sinistros — Notebook\n",
    "\n",
    "Pipeline completo (reprodutível) com preparação, análises, integração e relatório executivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488328da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "INPUT_AP = Path('/mnt/data/apolices.csv')\n",
    "INPUT_SI = Path('/mnt/data/sinistros_extract/sinistros.csv')\n",
    "OUT_DIR = Path('/mnt/data/analise_apolices')\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "df = pd.read_csv(INPUT_AP, low_memory=False)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b8462",
   "metadata": {},
   "source": [
    "## Integração com Sinistros e Export de Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "def to_date(s): return pd.to_datetime(s, dayfirst=True, errors='coerce')\n",
    "def to_num_br(s): \n",
    "    return pd.to_numeric(s.astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False), errors='coerce')\n",
    "\n",
    "# Detect (reuso simplificado)\n",
    "cols = {'apolice': 'Apólice', 'endosso': 'Endosso', 'desc_endosso': 'Descrição do Endosso', 'status': 'Status da Apólice', 'motivo_cancel': 'Motivo do Cancelamento', 'produto_nome': 'Nome do Produto', 'ramo_grupo': 'ID do Grupo do Ramo', 'uf': 'UF', 'cidade': 'Cidade', 'dt_emissao': 'Data de Emissão', 'dt_inicio': 'Data de Início da Vigência', 'dt_fim': 'Data de Fim da Vigência', 'sexo': 'Sexo', 'tipo_pessoa': 'Tipo de Pessoa'}\n",
    "\n",
    "# Numerics e datas básicas\n",
    "for c in [c for c in df.columns if any(k in c.lower() for k in ['valor','vl_','prêmio','premio','iof','custo','fracionamento'])]:\n",
    "    if (c + ' (num)') not in df.columns:\n",
    "        df[c + ' (num)'] = to_num_br(df[c])\n",
    "df['_dt_ini'] = to_date(df[cols['dt_inicio']]) if cols['dt_inicio'] else pd.NaT\n",
    "df['_dt_fim'] = to_date(df[cols['dt_fim']]) if cols['dt_fim'] else pd.NaT\n",
    "\n",
    "col_premio = next((c for c in df.columns if c.endswith(' (num)') and ('prêmio' in c.lower() or 'premio' in c.lower())), None)\n",
    "col_custo = next((c for c in df.columns if c.endswith(' (num)') and ('custo' in c.lower())), None)\n",
    "\n",
    "# Carregar sinistros (se existir)\n",
    "si_path = Path('/mnt/data/sinistros_extract/sinistros.csv')\n",
    "if si_path.exists():\n",
    "    si = pd.read_csv(si_path, low_memory=False)\n",
    "    si.columns = [c.strip() for c in si.columns]\n",
    "    col_si_apolice = 'Apólice' if 'Apólice' in si.columns else next((c for c in si.columns if 'apolice' in c.lower()), None)\n",
    "    col_si_valor = 'Valor do Evento de Sinistro' if 'Valor do Evento de Sinistro' in si.columns else next((c for c in si.columns if 'valor' in c.lower() and 'sinistro' in c.lower()), None)\n",
    "    col_si_data_ocorr = 'Data de Ocorrência do Sinistro' if 'Data de Ocorrência do Sinistro' in si.columns else next((c for c in si.columns if 'ocorr' in c.lower()), None)\n",
    "    col_si_num = 'Número do Sinistro' if 'Número do Sinistro' in si.columns else next((c for c in si.columns if 'sinistro' in c.lower() and 'número' in c.lower()), None)\n",
    "\n",
    "    si['_dt_ocorr'] = to_date(si.get(col_si_data_ocorr))\n",
    "    si['_valor_evento'] = to_num_br(si.get(col_si_valor))\n",
    "\n",
    "    ap_base = (\n",
    "        pd.concat([\n",
    "            df.groupby(cols['apolice'])[col_premio].sum(min_count=1).rename('premio_apolice') if cols['apolice'] and col_premio else pd.Series(dtype='float64'),\n",
    "            df.groupby(cols['apolice'])[col_custo].sum(min_count=1).rename('custo_apolice') if cols['apolice'] and col_custo else pd.Series(dtype='float64'),\n",
    "            df.groupby(cols['apolice'])[cols['produto_nome']].agg(lambda x: x.dropna().iloc[0] if len(x.dropna()) else np.nan).rename('produto') if cols['apolice'] and cols['produto_nome'] else pd.Series(dtype='object'),\n",
    "            df.groupby(cols['apolice'])[cols['uf']].agg(lambda x: x.dropna().iloc[0] if len(x.dropna()) else np.nan).rename('uf') if cols['apolice'] and cols['uf'] else pd.Series(dtype='object'),\n",
    "            df.groupby(cols['apolice'])[cols['status']].agg(lambda x: x.dropna().iloc[0] if len(x.dropna()) else np.nan).rename('status') if cols['apolice'] and cols['status'] else pd.Series(dtype='object'),\n",
    "            df.groupby(cols['apolice'])['_dt_ini'].min().rename('dt_inicio_min') if cols['apolice'] else pd.Series(dtype='datetime64[ns]'),\n",
    "        ], axis=1).reset_index()\n",
    "    )\n",
    "\n",
    "    si_agg = (\n",
    "        si.groupby(col_si_apolice)\n",
    "          .agg(qtd_sinistros=(col_si_num, 'nunique'),\n",
    "               primeiro_sinistro=('_dt_ocorr','min'),\n",
    "               valor_sinistros_total=('_valor_evento','sum'))\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    join_ap = ap_base.merge(si_agg, how='left', left_on=cols['apolice'], right_on=col_si_apolice)\n",
    "    join_ap['tem_sinistro'] = join_ap['qtd_sinistros'].fillna(0).gt(0)\n",
    "    join_ap['sinistralidade'] = join_ap['valor_sinistros_total'] / join_ap['premio_apolice']\n",
    "    join_ap['tempo_ate_primeiro_sinistro_dias'] = (join_ap['primeiro_sinistro'] - join_ap['dt_inicio_min']).dt.days\n",
    "\n",
    "    join_ap.to_csv(OUT_DIR/'20_join_por_apolice.csv', index=False)\n",
    "\n",
    "    def summarize_by(group_col, min_pol=100):\n",
    "        g = (\n",
    "            join_ap.groupby(group_col, dropna=False)\n",
    "                   .agg(apolices=(join_ap.columns[0], 'nunique'),\n",
    "                        apolices_com_sinistro=('tem_sinistro','sum'),\n",
    "                        premio_total=('premio_apolice','sum'),\n",
    "                        sinistros_total=('valor_sinistros_total','sum'))\n",
    "                   .assign(incidencia_sinistro=lambda d: d['apolices_com_sinistro']/d['apolices'],\n",
    "                           sinistralidade=lambda d: d['sinistros_total']/d['premio_total'])\n",
    "                   .sort_values('sinistralidade', ascending=False)\n",
    "        )\n",
    "        return g[g['apolices']>=min_pol]\n",
    "\n",
    "    by_produto = summarize_by('produto', 100) if 'produto' in join_ap.columns else None\n",
    "    by_uf = summarize_by('uf', 100) if 'uf' in join_ap.columns else None\n",
    "    by_status = summarize_by('status', 100) if 'status' in join_ap.columns else None\n",
    "\n",
    "    if by_produto is not None: by_produto.to_csv(OUT_DIR/'21_sinistralidade_por_produto.csv')\n",
    "    if by_uf is not None: by_uf.to_csv(OUT_DIR/'22_sinistralidade_por_uf.csv')\n",
    "    if by_status is not None: by_status.to_csv(OUT_DIR/'23_sinistralidade_por_status.csv')\n",
    "\n",
    "    valid = join_ap['tem_sinistro'] & join_ap['tempo_ate_primeiro_sinistro_dias'].notna() & (join_ap['tempo_ate_primeiro_sinistro_dias']>=0)\n",
    "    tempo = join_ap.loc[valid, 'tempo_ate_primeiro_sinistro_dias']\n",
    "    tempo_stats = None\n",
    "    if len(tempo):\n",
    "        tempo_stats = {\n",
    "            'qtd_validas': int(valid.sum()),\n",
    "            'mediana': float(tempo.median()),\n",
    "            'media': float(tempo.mean()),\n",
    "            'q1': float(tempo.quantile(0.25)),\n",
    "            'q3': float(tempo.quantile(0.75)),\n",
    "            'pct_ate_30d': float((tempo<=30).mean()),\n",
    "            'pct_ate_90d': float((tempo<=90).mean())\n",
    "        }\n",
    "    tempo_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bc237",
   "metadata": {},
   "source": [
    "## Relatório Executivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "OUT = Path('/mnt/data/analise_apolices')\n",
    "\n",
    "def read_csv(name):\n",
    "    p = OUT/name\n",
    "    return pd.read_csv(p, index_col=0) if p.exists() else None\n",
    "\n",
    "join_path = OUT/'20_join_por_apolice.csv'\n",
    "join_ap = pd.read_csv(join_path, low_memory=False) if join_path.exists() else None\n",
    "\n",
    "lines = []\n",
    "if join_ap is not None:\n",
    "    apolices = join_ap.iloc[:,0].nunique()\n",
    "    ap_sin = int(join_ap['tem_sinistro'].sum())\n",
    "    premio = float(join_ap['premio_apolice'].sum(skipna=True))\n",
    "    sin_total = float(join_ap['valor_sinistros_total'].sum(skipna=True))\n",
    "    sin_glob = sin_total/premio if premio else float('nan')\n",
    "\n",
    "    valid = join_ap['tem_sinistro'] & join_ap['tempo_ate_primeiro_sinistro_dias'].notna() & (join_ap['tempo_ate_primeiro_sinistro_dias']>=0)\n",
    "    tempo = join_ap.loc[valid, 'tempo_ate_primeiro_sinistro_dias']\n",
    "\n",
    "    lines.append(f\"- **Apólices (únicas)**: {apolices:,}\")\n",
    "    lines.append(f\"- **Apólices com sinistro**: {ap_sin:,}  ({ap_sin/apolices:.2%})\")\n",
    "    lines.append(f\"- **Prêmio total**: R$ {premio:,.0f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\"))\n",
    "    lines.append(f\"- **Sinistros total**: R$ {sin_total:,.0f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\"))\n",
    "    lines.append(f\"- **Sinistralidade global**: {sin_glob:.2%}\")\n",
    "\n",
    "    if len(tempo):\n",
    "        lines.append(f\"- **Tempo até 1º sinistro (mediana)**: {tempo.median():.0f} dias (média {tempo.mean():.0f} | Q1–Q3 {tempo.quantile(0.25):.0f}–{tempo.quantile(0.75):.0f} | ≤30d {(tempo<=30).mean():.2%} | ≤90d {(tempo<=90).mean():.2%})\")\n",
    "\n",
    "# Cancelamento (se gerado)\n",
    "cancel_uf = read_csv(\"08_cancel_por_uf.csv\")\n",
    "if cancel_uf is not None and not cancel_uf.empty:\n",
    "    worst_uf = cancel_uf.sort_values(\"taxa_cancel\", ascending=False).head(3)\n",
    "    lines.append(\"\\n**UFs com maior taxa de cancelamento**:\")\n",
    "    for idx, r in worst_uf.iterrows():\n",
    "        lines.append(f\"- {idx}: taxa {r['taxa_cancel']:.2%} (apólices {int(r['qtd'])}, canceladas {int(r['cancelados'])})\")\n",
    "\n",
    "cancel_prod = read_csv(\"06_cancel_por_produto.csv\")\n",
    "if cancel_prod is not None and not cancel_prod.empty:\n",
    "    worst_prod = cancel_prod.sort_values(\"taxa_cancel\", ascending=False).head(3)\n",
    "    lines.append(\"\\n**Produtos com maior taxa de cancelamento**:\")\n",
    "    for idx, r in worst_prod.iterrows():\n",
    "        lines.append(f\"- {idx}: taxa {r['taxa_cancel']:.2%} (apólices {int(r['qtd'])}, canceladas {int(r['cancelados'])})\")\n",
    "\n",
    "display(Markdown(\"\\n\".join(lines) if lines else \"Sem dados para o relatório.\"))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
